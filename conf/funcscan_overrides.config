/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Custom overrides for nf-core/funcscan
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    1. Pin pyhmmer<0.12 for GECCO and DeepBGC to fix:
           AttributeError: 'str' object has no attribute 'decode'
       (pyhmmer >=0.12 changed hmm.accession from bytes to str)
    2. Resource caps for DTU HPC — 20-core / 128 GB nodes.
       funcscan's base.config has no ceiling guard — retries scale CPUs/memory
       unboundedly and exceed node limits. Hard-coded values aligned with bacass's
       heaviest processes, which are proven to fit DTU HPC.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// BACASS_DIR is exported by setup.sh, available at runtime
def bacassDir = System.getenv('BACASS_DIR') ?: '/work3/josne/github/bacass'

process {
    // ── pyhmmer<0.12 fixes ─────────────────────────────────────────────────────
    withName: 'GECCO_RUN' {
        conda = "${bacassDir}/conf/gecco_environment.yml"
        // GECCO module's mv loop fails with "same file" when input.baseName == prefix.
        // GECCO itself succeeds — outputs are already correctly named. Ignore the mv error.
        errorStrategy = 'ignore'
    }
    withName: 'DEEPBGC_PIPELINE' {
        conda = "${bacassDir}/conf/deepbgc_environment.yml"
        // DeepBGC's mv loop fails with "same file" when genome.baseName == prefix.
        // DeepBGC itself succeeds — outputs are already correctly named.
        // Ignore exit 1 (mv error) but still retry on exit 130 (OOM/timeout).
        errorStrategy = { task.exitStatus == 1 ? 'ignore' : 'retry' }
    }
    withName: 'AMPCOMBI2_COMPLETE' {
        // ampcombi complete requires >=2 summary files but single-sample runs only produce 1.
        // This is a summarization step — safe to ignore for single-sample runs.
        errorStrategy = 'ignore'
    }

    // ── DTU HPC resource caps ──────────────────────────────────────────────────
    // Reference ceiling from bacass (proven on cluster): 20 CPUs / 120 GB max.

    // process_high: funcscan default → 12*attempt CPUs / 72.GB*attempt memory.
    //   attempt 2 uncapped: 24 CPU / 144 GB  ✗  (no 20-core / 128 GB node can host this)
    //   after fix:          12 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withLabel: 'process_high' {
        cpus   = 12
        memory = { 60.GB * task.attempt }
        time   = { 16.h * task.attempt }
    }

    // process_high_memory: funcscan default → 200.GB*attempt.
    //   attempt 1 uncapped: 200 GB  ✗  (exceeds all 128 GB nodes)
    //   after fix:          120 GB (fixed, matches bacass hard ceiling)  ✓
    withLabel: 'process_high_memory' {
        memory = 120.GB
    }

    // AMPCOMBI2_PARSETABLES: funcscan default → 16*attempt CPUs.
    //   attempt 2 uncapped: 32 CPUs  ✗  (no node has 32 cores)
    //   after fix:          16 CPUs (fixed)  ✓
    withName: 'AMPCOMBI2_PARSETABLES' {
        cpus = 16
    }

    // ANTISMASH_ANTISMASH: funcscan default → 8*attempt CPUs / 64.GB*attempt memory.
    //   attempt 2 uncapped: 16 CPU / 128 GB — fits but leaves no OS headroom
    //   after fix:          8 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withName: 'ANTISMASH_ANTISMASH' {
        cpus   = 8
        memory = { 60.GB * task.attempt }
        time   = { 12.h * task.attempt }
    }

    // BAKTA_BAKTA: same ceiling issue as ANTISMASH. Skipped when pre-annotated input
    // is provided (our default), but capped defensively.
    //   attempt 2 uncapped: 16 CPU / 128 GB — no OS headroom
    //   after fix:          8 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withName: 'BAKTA_BAKTA' {
        cpus   = 8
        memory = { 60.GB * task.attempt }
        time   = { 8.h * task.attempt }
    }
}
