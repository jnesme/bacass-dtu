/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Custom overrides for nf-core/funcscan
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    1. Pin pyhmmer<0.12 for GECCO and DeepBGC to fix:
           AttributeError: 'str' object has no attribute 'decode'
       (pyhmmer >=0.12 changed hmm.accession from bytes to str)
    2. Resource caps for DTU HPC — 20-core / 128 GB nodes.
       funcscan's base.config has no ceiling guard — retries scale CPUs/memory
       unboundedly and exceed node limits. Hard-coded values aligned with bacass's
       heaviest processes, which are proven to fit DTU HPC.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// BACASS_DIR is exported by setup.sh, available at runtime
def bacassDir = System.getenv('BACASS_DIR') ?: '/work3/josne/github/bacass'

process {
    // ── pyhmmer<0.12 fixes ─────────────────────────────────────────────────────
    withName: 'GECCO_RUN' {
        conda = "${bacassDir}/conf/gecco_environment.yml"
        // GECCO module's mv loop fails with "same file" when input.baseName == prefix
        // (i.e. when meta.id matches the assembly basename, which is always the case here).
        // errorStrategy = 'ignore' was tried but drops the output channel — results never
        // get published. Fix: set ext.prefix to a different value so mv succeeds and NF
        // collects outputs normally. The suffix is cosmetic; downstream COMBGC uses meta.id.
        ext.prefix = { "${meta.id}_gecco" }
    }
    withName: 'DEEPBGC_PIPELINE' {
        conda = "${bacassDir}/conf/deepbgc_environment.yml"
        // DeepBGC mv collision analysis:
        //   The module script does two mv steps:
        //     1. mv "${genome.baseName}/" "${prefix}/"   (dir rename)
        //     2. for i in $(find -name '${genome.baseName}*' -type f); do
        //            mv $i ${i/${genome.baseName}/${prefix}}
        //        done
        //   Default (prefix == meta.id == "S0679", genome.baseName == "S0679"):
        //     Step 1: skipped (same name — bash condition false).
        //     Step 2: ${i/S0679/S0679} = rename-to-self → bash -e exits with error.
        //   Fix: use a static prefix that shares no substring with any sample ID.
        //     "deepbgc" never appears in any sample ID (S0679, S0344, etc.), so:
        //     Step 1: mv S0679/ deepbgc/  ✓
        //     Step 2: ${i/S0679/deepbgc} where i = ./deepbgc/S0679.bgc.tsv
        //             → ./deepbgc/deepbgc.bgc.tsv  ✓  (substitution only hits filename)
        //     Module output: ${prefix}/${prefix}.bgc.tsv = deepbgc/deepbgc.bgc.tsv  ✓
        //     COMBGC receives the bgc_tsv channel entry and runs with all three tools.
        //   Why ${meta.id}_deepbgc fails: after dir rename to S0679_deepbgc/,
        //     ${i/S0679/S0679_deepbgc} where i = ./S0679_deepbgc/S0679.bgc.tsv
        //     → the substitution hits the directory portion first → ./S0679_deepbgc_deepbgc/... ✗
        ext.prefix = "deepbgc"
    }
    withName: 'AMPCOMBI2_COMPLETE' {
        // ampcombi complete requires >=2 summary files but single-sample runs only produce 1.
        // This is a summarization step — safe to ignore for single-sample runs.
        errorStrategy = 'ignore'
    }

    // ── DTU HPC resource caps ──────────────────────────────────────────────────
    // Reference ceiling from bacass (proven on cluster): 20 CPUs / 120 GB max.

    // process_high: funcscan default → 12*attempt CPUs / 72.GB*attempt memory.
    //   attempt 2 uncapped: 24 CPU / 144 GB  ✗  (no 20-core / 128 GB node can host this)
    //   after fix:          12 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withLabel: 'process_high' {
        cpus   = 12
        memory = { 60.GB * task.attempt }
        time   = { 16.h * task.attempt }
    }

    // process_high_memory: funcscan default → 200.GB*attempt.
    //   attempt 1 uncapped: 200 GB  ✗  (exceeds all 128 GB nodes)
    //   after fix:          120 GB (fixed, matches bacass hard ceiling)  ✓
    withLabel: 'process_high_memory' {
        memory = 120.GB
    }

    // AMPCOMBI2_PARSETABLES: funcscan default → 16*attempt CPUs.
    //   attempt 2 uncapped: 32 CPUs  ✗  (no node has 32 cores)
    //   after fix:          16 CPUs (fixed)  ✓
    withName: 'AMPCOMBI2_PARSETABLES' {
        cpus = 16
    }

    // ANTISMASH_ANTISMASH: funcscan default → 8*attempt CPUs / 64.GB*attempt memory.
    //   attempt 2 uncapped: 16 CPU / 128 GB — fits but leaves no OS headroom
    //   after fix:          8 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withName: 'ANTISMASH_ANTISMASH' {
        cpus   = 8
        memory = { 60.GB * task.attempt }
        time   = { 12.h * task.attempt }
    }

    // BAKTA_BAKTA: same ceiling issue as ANTISMASH. Skipped when pre-annotated input
    // is provided (our default), but capped defensively.
    //   attempt 2 uncapped: 16 CPU / 128 GB — no OS headroom
    //   after fix:          8 CPU (fixed) / 60.GB*attempt → 60 / 120 GB  ✓
    withName: 'BAKTA_BAKTA' {
        cpus   = 8
        memory = { 60.GB * task.attempt }
        time   = { 8.h * task.attempt }
    }
}
